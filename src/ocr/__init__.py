"""
OCR çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

å‰å‡¦ç†ã€æ–‡å­—åˆ†å‰²ã€Deep Learningæ¤œè¨¼ã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’çµ±åˆã—ãŸãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
"""

import json
import webbrowser
from pathlib import Path

from PIL import Image

from src.config import settings
from src.ocr.adjuster import IterativeRefiner
from src.ocr.preprocessor import Preprocessor
from src.ocr.report import ReportGenerator
from src.ocr.segmenter import CharacterSegmenter
from src.ocr.verifier import CharacterVerifier


class OCRPipeline:
    """
    OCRçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (Deep Learningæ¤œè¨¼ä»˜ã)

    1. è°·ç‚¹æ¤œå‡ºã§åˆæœŸåˆ†å‰²
    2. manga-ocr ã§å„æ–‡å­—ã‚’æ¤œè¨¼
    3. ä¸ä¸€è‡´ãŒã‚ã‚Œã°å¢ƒç•Œã‚’èª¿æ•´ã—ã¦å†æ¤œè¨¼
    4. HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    """

    def __init__(self):
        self.output_dir = settings.output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.preprocessor = Preprocessor()
        self.segmenter = CharacterSegmenter()
        self.verifier = CharacterVerifier()
        self.refiner = IterativeRefiner(max_iterations=3)
        self.report_generator = ReportGenerator(self.output_dir)

    def process(self) -> Path:
        """ç”»åƒå‡¦ç† â†’ æ–‡å­—åˆ†å‰² â†’ æ¤œè¨¼ãƒ»èª¿æ•´ â†’ HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("ğŸ“ OCRå‡¦ç†ã‚’é–‹å§‹...")

        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        input_path = self._find_input_image()
        anno_path = settings.input_dir / "annotation.txt"

        if input_path is None:
            print(f"âŒ Error: Input image not found in {settings.input_dir}")
            return None

        if not anno_path.exists():
            print(f"âŒ Error: Annotation file not found: {anno_path}")
            return None

        # ç”»åƒã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®èª­ã¿è¾¼ã¿
        image = Image.open(input_path).convert("RGB")
        with open(anno_path, encoding="utf-8") as f:
            anno_lines = [line.strip() for line in f if line.strip()]

        target_text = "".join(anno_lines)
        print(f"  ğŸ“Š Target: {len(target_text)} chars ({len(anno_lines)} lines)")

        # 1. å‰å‡¦ç†
        _, binary = self.preprocessor.process(image)
        print("  âœ… Preprocessing complete")

        # 2. è¡Œæ¤œå‡º
        line_regions = self.preprocessor.detect_lines(binary)
        print(f"  ğŸ“ Detected {len(line_regions)} lines")

        if len(line_regions) != len(anno_lines):
            print(
                f"  âš ï¸ Warning: Line count mismatch (detected={len(line_regions)}, annotation={len(anno_lines)})"
            )
            num_proc = min(len(line_regions), len(anno_lines))
        else:
            num_proc = len(line_regions)

        all_results = []
        char_idx = 0
        total_verified = 0
        total_matched = 0

        # 3. è¡Œã”ã¨ã®å‡¦ç†
        for line_no in range(num_proc):
            y1, y2 = line_regions[line_no]
            line_text = anno_lines[line_no]
            line_binary = binary[y1:y2, :]
            line_image = image.crop((0, y1, image.width, y2))

            print(f"  ğŸ“ Line {line_no + 1}: '{line_text[:15]}...' ({len(line_text)} chars)")

            # åˆæœŸåˆ†å‰²
            initial_boundaries = self.segmenter.segment(line_binary, len(line_text))

            # åå¾©çš„æ¤œè¨¼ãƒ»èª¿æ•´
            refined_boundaries = self.refiner.refine(
                initial_boundaries,
                line_binary,
                line_image,
                list(line_text),
                self.verifier,
            )

            # æœ€çµ‚æ¤œè¨¼
            char_images = []
            for x_start, x_end in refined_boundaries:
                if x_end > x_start:
                    char_images.append(line_image.crop((x_start, 0, x_end, line_image.height)))
                else:
                    char_images.append(Image.new("RGB", (10, 10), "white"))

            verification_results = self.verifier.verify_batch(char_images, list(line_text))
            line_matched = sum(1 for is_match, _ in verification_results if is_match)
            total_verified += len(line_text)
            total_matched += line_matched
            print(f"    âœ… Verified: {line_matched}/{len(line_text)} chars matched")

            # æ–‡å­—ç”»åƒã®ä¿å­˜
            for i, (x_start, x_end) in enumerate(refined_boundaries):
                if i >= len(line_text):
                    break

                char = line_text[i]
                is_match, recognized = (
                    verification_results[i] if i < len(verification_results) else (False, "?")
                )

                # çµ¶å¯¾åº§æ¨™
                char_x, char_y = x_start, y1
                char_w, char_h = x_end - x_start, y2 - y1

                # ãƒãƒ¼ã‚¸ãƒ³ã‚’è¿½åŠ 
                margin = 3
                crop_x1 = max(0, char_x - margin)
                crop_y1 = max(0, char_y - margin)
                crop_x2 = min(image.width, char_x + char_w + margin)
                crop_y2 = min(image.height, char_y + char_h + margin)

                # ä¿å­˜
                char_img = image.crop((crop_x1, crop_y1, crop_x2, crop_y2))
                char_filename = f"char_{char_idx:03d}_{char}.png"
                char_img.save(self.output_dir / char_filename)

                all_results.append(
                    {
                        "index": char_idx,
                        "text": char,
                        "recognized": recognized,
                        "verified": is_match,
                        "bbox": [int(char_x), int(char_y), int(char_w), int(char_h)],
                        "image_path": char_filename,
                    }
                )
                char_idx += 1

        # ç²¾åº¦è¨ˆç®—
        accuracy = total_matched / total_verified if total_verified > 0 else 0
        print(f"  ğŸ¯ Overall accuracy: {accuracy:.1%} ({total_matched}/{total_verified})")

        # 4. çµæœJSONã®ä¿å­˜
        final_output = {
            "source_path": str(input_path),
            "metadata": {
                "total_characters": len(all_results),
                "detector": "Valley Detection + manga-ocr Verification",
                "accuracy": accuracy,
                "verified": total_matched,
                "total": total_verified,
            },
            "characters": all_results,
        }

        result_json_path = self.output_dir / "result.json"
        with open(result_json_path, "w", encoding="utf-8") as f:
            json.dump(final_output, f, ensure_ascii=False, indent=2)

        print(f"  ğŸ’¾ Result saved: {len(all_results)} characters")

        # 5. HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_path = self.report_generator.generate(final_output)
        print(f"  ğŸ“„ Report generated: {report_path}")

        # 6. ãƒ–ãƒ©ã‚¦ã‚¶ã§è¡¨ç¤º
        webbrowser.open(f"file://{report_path.resolve()}")
        print("âœ… Complete! Opening report in browser...")

        return report_path

    def _find_input_image(self) -> Path | None:
        """å…¥åŠ›ç”»åƒã‚’æ¤œç´¢"""
        for ext in ["png", "jpg", "jpeg", "PNG", "JPG", "JPEG"]:
            path = settings.input_dir / f"image.{ext}"
            if path.exists():
                return path
        return None
